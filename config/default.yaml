# LAIOS Configuration

# LLM Provider Settings
llm:
  provider: "ollama"  # Options: ollama, openai, anthropic
  model: "gemma3:4b"
  base_url: "http://localhost:11434"
  temperature: 0.5          # Lower = faster sampling, more deterministic
  max_tokens: 2048          # Reduced from 4096 - generates less, responds faster
  timeout: 120              # Increased to avoid premature timeouts
  keep_alive: "30m"         # Keep model loaded in RAM for 30 min (avoids cold-start reload)
  num_ctx: 4096             # Smaller context window = faster inference, less RAM

# Agent Behavior
agent:
  # Trust level: paranoid (always confirm), balanced (confirm risky), autonomous (auto-execute)
  trust_level: "balanced"
  max_planning_iterations: 3
  max_replanning_attempts: 2
  enable_reflection: true

# Memory Configuration
memory:
  # Short-term memory (conversation buffer)
  short_term:
    max_messages: 50
    persist: true
    storage_path: "~/.laios/memory/sessions"
  
  # Long-term memory (vector embeddings)
  long_term:
    enabled: true
    provider: "chromadb"
    storage_path: "~/.laios/memory/longterm"
    embedding_model: "all-MiniLM-L6-v2"
    max_results: 10
  
  # Episodic memory (task history)
  episodic:
    enabled: true
    storage_path: "~/.laios/memory/episodes.db"
    retention_days: 90

# Tool Configuration
tools:
  # Built-in tools to enable
  enabled:
    - filesystem
    - shell
    - web
    - code
  
  # Tool permissions
  permissions:
    filesystem:
      allowed_paths:
        - "~/"
        - "/tmp"
      denied_paths:
        - "/etc"
        - "/sys"
        - "~/.ssh"
      max_file_size_mb: 100
    
    shell:
      allowed_commands:
        - "ls"
        - "cat"
        - "grep"
        - "find"
      deny_sudo: true
      timeout: 30
    
    web:
      max_request_size_mb: 10
      timeout: 30
      allowed_domains: []  # Empty = all allowed
      denied_domains:
        - "localhost"
        - "127.0.0.1"

# Execution Settings
execution:
  mode: "sync"  # Options: sync, async
  max_parallel_tasks: 5
  task_timeout: 25  # seconds
  enable_sandboxing: false  # Future: Docker/VM isolation
  session_ttl_minutes: 60  # Auto-expire idle sessions (0 = disabled)

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "structured"  # structured, plain
  output: "console"  # console, file, both
  file_path: "~/.laios/logs/laios.log"
  max_file_size_mb: 50
  backup_count: 5

# UI Settings
ui:
  cli:
    color: true
    rich_formatting: true
    show_plan_before_execution: true
  
  api:
    host: "127.0.0.1"
    port: 8000
    enable_cors: false
    allowed_origins: []

# Plugin Settings
plugins:
  enabled: true
  directories:
    - "~/.laios/plugins"
    - "./plugins"
  auto_load: false

# Production Hardening
hardening:
  # Circuit breaker for LLM calls
  circuit_breaker:
    failure_threshold: 5
    recovery_timeout: 30  # seconds

  # Rate limiting
  rate_limiting:
    enabled: true
    rate: 10.0           # requests per second per key
    capacity: 20         # burst capacity
    global_rate: 50.0    # global requests per second
    global_capacity: 100

  # API key authentication
  auth:
    enabled: false
    keys_file: "~/.laios/api_keys.json"

  # Audit logging
  audit:
    enabled: true
    log_path: "~/.laios/logs/audit.log"
    max_bytes: 10485760  # 10 MB per file
    backup_count: 5

  # Input sanitization
  sanitization:
    max_input_length: 10000
    max_path_length: 4096

  # Graceful shutdown
  shutdown:
    timeout: 30  # seconds to wait for cleanup
